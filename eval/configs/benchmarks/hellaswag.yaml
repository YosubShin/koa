# HellaSwag
# Tests commonsense natural language inference
# Choose most plausible continuation of a sentence

model:
  model_name: "meta-llama/Llama-3.1-8B-Instruct"
  model_max_length: 2048
  dtype: "bfloat16"
  attn_implementation: "flash_attention_2"

generation:
  per_device_batch_size: 8  # Can use larger batch for this task
  temperature: 0.0
  max_new_tokens: 128

tasks:
  - backend: "lm_harness"
    task: "hellaswag"
    num_fewshot: 10
    output_path: "./eval_results/hellaswag"
