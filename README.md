# koa

A lightweight command-line companion for the University of Hawai'i KOA cluster. The tool focuses on one job: making it easy to sync code, submit jobs, and monitor their life cycle from your local workstation.

---

## Highlights
- **Job submission pipeline** – copy a script, infer sensible defaults, and hand it to `sbatch` with a single command.
- **Workspace snapshots** – every submission bundles the exact repo state so jobs run with reproducible code and configs.
- **Run manifests** – each submission stores git state and relevant untracked files alongside the job results for reproducibility.
- **Global setup** – one-time `koa setup` captures usernames, workspace roots, and a default CUDA Toolkit version for each backend.
- **Run catalog** – every submission is indexed locally so you can list, sync, and inspect historical runs.
- **Plain Python package** – small dependency footprint and no bundled training/evaluation code.

---

# Prerequisites

Add this to `~/.bashrc` in HPC environment in order to avoid using up disk quota.
```bash
export XDG_CACHE_HOME=<path to your scratch folder. eg. /mnt/lustre/koa/scratch/yosubs/cache>
export HF_HOME=$XDG_CACHE_HOME/hf
export TRITON_CACHE_DIR=$XDG_CACHE_HOME/triton
export TORCH_HOME=$XDG_CACHE_HOME/torch
export PIP_CACHE_DIR=$XDG_CACHE_HOME/pip
export TMPDIR=$XDG_CACHE_HOME/tmp
export APPTAINER_CACHEDIR=$XDG_CACHE_HOME/apptainer
```

Setup ssh config at `~/.ssh/config` so that it doesn't keep asking for multi-factor authentication.
```bash
Host koa koa.its.hawaii.edu
  HostName koa.its.hawaii.edu
  User <username: e.g. yosubs>
  IdentitiesOnly yes
  IdentityFile <path to secret key: e.g. ~/.ssh/koa_key>
  ControlMaster auto
  ControlPath ~/.ssh/cm-%C
  ControlPersist 1h
  ServerAliveInterval 60
  ServerAliveCountMax 3
  TCPKeepAlive yes
  StrictHostKeyChecking accept-new
```

## Installation

```bash
# Recommended: pipx keeps koa isolated but available everywhere
# (install pipx with `python3 -m pip install --user pipx` then `python3 -m pipx ensurepath` if needed)
pipx install --force git+https://github.com/YosubShin/koa.git

# Alternatively: per-user install (ensure ~/.local/bin is on PATH)
python3 -m pip install --user git+https://github.com/YosubShin/koa.git

# Development: editable install inside a throwaway venv
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip setuptools wheel
pip install -e .
```

The CLI installs the entry point `koa`.

---

## Configure access

1. Run `koa setup` (once per machine) to capture your KOA username, host, and the global workspace roots on KOA and locally. The global config lives at `~/.config/koa/config.yaml`.
   - The global config now supports multiple Slurm backends via a top-level `backends:` list. Each entry records the connection + workspace settings for a `cluster_name` (e.g. `koa` or `delta`). `koa setup` targets the default `koa` backend; pass `--backend delta` to add or update another cluster.
   - Use `--default-constraint hopper` (or leave blank) to set per-cluster Slurm constraints; this keeps KOA on `hopper` nodes while clusters like Delta can omit constraints entirely.
   - Use `--default-gres gpu:a100:1` (or similar) if you want a default `--gres` line added to submissions for a backend.
   - Use `--cuda-version 12.4` (or leave blank for 12.8) to set the CUDA Toolkit minor version that should be installed automatically for that backend.
   - Provide `--dashboard-base-url https://<ondemand-host>/pun/sys/dashboard/files/fs` if you want web links in the dashboard to jump straight into your OnDemand file browser.
2. Inside each repository, run `koa init` to generate a minimal `koa-config.yaml` plus helper scripts. Use `--cuda-version` if this project needs a different CUDA Toolkit minor version from the backend default.
3. (Optional) Update `env_watch` and `snapshot_excludes` in `koa-config.yaml` if your project needs custom lockfiles or directories you want to skip during snapshots.

The CLI automatically discovers `koa-config.yaml` by walking up from the current working directory. Environment variables such as `KOA_USER`, `KOA_HOST`, `KOA_IDENTITY_FILE`, `KOA_REMOTE_ROOT`, `KOA_LOCAL_ROOT`, `KOA_DEFAULT_PARTITION`, `KOA_DEFAULT_CONSTRAINT`, `KOA_CUDA_VERSION`, `KOA_ENV_WATCH`, `KOA_PROXY_COMMAND`, and `KOA_DASHBOARD_BASE_URL` can override the saved configuration at runtime.

Example `koa-config.yaml` generated by `koa init`:

```yaml
project: my-awesome-project

default_backend: koa

cuda_minor_version: 12.8

env_watch:
  - scripts/setup_env.sh
  - requirements.txt
  - pyproject.toml

# Always forward these env vars when submitting (if set locally)
env_pass:
  - MODEL_NAME
  - DATA_ROOT
```

### Sample multi-backend ~/.config/koa/config.yaml

```yaml
default_backend: koa

backends:
  - cluster_name: koa
    user: yosubs
    host: koa.its.hawaii.edu
    remote_root: /mnt/lustre/koa/scratch/yosubs/koa-cli
    local_root: ~/koa-projects
    default_partition: kill-shared
    default_constraint: hopper
    default_gres: gpu:a100:1
    cuda_minor_version: 12.8

  - cluster_name: delta
    user: yosubs
    host: login.delta.ncsa.illinois.edu
    remote_root: /projects/yosubs/koa-cli
    local_root: ~/delta-projects
    default_partition: gpuA100x4  # leave blank if cluster picks a default
    default_constraint: ""        # unset to avoid hopper-only behavior
    default_gres: gpu:a100:1
    cuda_minor_version: 12.4
```

Run `koa setup --backend delta` to add or update the `delta` block; omit flags to keep existing values. Use `--backend <name>` on commands (or `KOA_BACKEND`) to pick the cluster when submitting.
Set per-cluster constraints by adding `default_constraint: hopper` under the relevant backend in `~/.config/koa/config.yaml` (leave it unset for clusters that don't need a constraint). Project-level `koa-config.yaml` can override or clear it if needed.
Add optional `snapshot_excludes:` if you want to skip additional files or directories during submission snapshots (e.g., raw datasets or build artifacts). Patterns without a slash match any basename (`data` matches every `data/` folder). Patterns with a slash match repo-relative paths (`data/hf` matches only that path). Prefix a basename with `./` or `/` to target only the repo root (`./data` excludes the top-level `data/` only).



---

## Everyday workflow

```bash
# 0. (First time) Configure your KOA defaults
koa setup --user $USER

# 0b. (Per project) Bootstrap a repo with config + scripts
koa init

# 1. Check connectivity and cluster health
koa check

# 2. Submit a job script (declare GPU resources in the SLURM script, or add `--gpus` for a generic count)
koa submit scripts/basic_job.slurm --time 01:00:00 --desc "baseline"
# every submission writes a repo snapshot + run metadata under <local results>/<job-id>/
  # run_metadata/ includes env_hashes.json for watched setup files
# forward local env into the job (NAME pulls from your shell; NAME=val sets explicitly)
MODEL_NAME=qwen3-vl-4b-instruct koa submit scripts/basic_job.slurm --env MODEL_NAME
koa submit scripts/basic_job.slurm --env MODEL_NAME=qwen3-vl-4b-instruct --env DATA_ROOT=/data/run123

# 3. Monitor jobs and inspect runs
koa jobs
koa cancel <job-id>
koa logs <job-id> --follow
koa runs list
koa dashboard  # launches the Streamlit view
```

Every submitted job includes a `run_metadata/` folder under its results directory containing `manifest.json`, `git_head.txt`, `git_status.txt`, `env_hashes.json`, and any untracked files that were present locally when you launched the run.

---

## CLI reference

- `check` – run a quick SSH round-trip and display `sinfo` output.
- `setup` – configure global defaults (user, workspace roots, default CUDA Toolkit version).
- `init` – scaffold project config and helper scripts using global defaults.
- `jobs` – list your queued and running jobs via `squeue`.
- `dashboard` – open the Streamlit dashboard with job history, logs, and GPU node views.
- `submit` – copy a script and call `sbatch`; use `--sbatch-arg` for raw overrides. Add flags like `--gpus` (generic count), `--constraint hopper`, or `--desc` to control resources and the timestamped results folder name. Forward env vars with `--env NAME` or `--env NAME=value`, and set defaults in `env_pass` within `koa-config.yaml`.
- `cancel` – stop a job by ID with `scancel`.
- `logs` – stream or inspect a job's stdout/stderr in real time via `tail` (stored at `<remote results dir>/<job-id>/job.log` and `job.err`).
- `runs` – sync and inspect the local catalog of submitted jobs.
  - `koa runs list` shows recent submissions (most recent first).
  - `koa runs sync` updates Slurm status and downloads completed runs into the local mirror automatically.
  - `koa runs show <job-id>` prints the recorded metadata (git commit, env hashes, locations) for a single run.

Each command accepts `--config /path/to/config.yaml` if you need to swap between multiple KOA accounts, and `--backend <cluster_name>` to target a specific Slurm backend when you have more than one configured.

---

## Dashboard

KOA ships with a built-in Streamlit dashboard; no extra install steps are required.

Launch the Streamlit UI via:

```bash
koa dashboard
```

Features:

- **Job catalog** – combines the local `runs.json` history with live `squeue`/`sacct` data so you can review submission, start/end times, GPU allocations, Slurm reasons, and recorded manifests.
- **Log viewer** – fetches stdout/stderr from the local mirror when available and falls back to streaming the remote log path via SSH.
- **Cluster links** – set `dashboard_base_url` (or `KOA_DASHBOARD_BASE_URL`) to your Open OnDemand file-browser prefix to unlock per-job shortcuts to the run folder.
- **Run notes** – the optional `--desc` flag is saved with each submission, and you can edit or clear descriptions (or delete stale runs) directly inside the dashboard.
- **Resource usage** – surfaces reported TRES allocations/usage, Max RSS, and live `sstat` samples for running jobs when available.
- **GPU inventory** – mirrors `sinfo -N -o "%N|%G|%T|%C|%P"` so you can see node states, partitions, and GPU models at a glance.

Use the sidebar’s refresh button to force a reread of Slurm data; otherwise the dashboard automatically refreshes on every interaction (with remote calls cached for ~30 seconds).

---

## Directory layout

`koa setup` captures two roots:

- **Remote root** (e.g. `/mnt/lustre/koa/scratch/<user>/koa-cli`)
- **Local root** (e.g. `~/.koa-cli`)

For a project named `<project>`, the CLI derives:

```
Remote: <remote_root>/projects/<project>/jobs/<timestamp[_desc]>/{repo,run_metadata,results,job.log,job.err}
Local : <local_root>/projects/<project>/jobs/<timestamp[_desc]>/{repo,run_metadata,results,job.log,job.err}
```

- `repo/` contains the exact snapshot submitted with the job.
- `run_metadata/` holds manifests, git info, and environment hashes.
- `results/` is where your job writes outputs; `koa runs sync` copies the entire run directory (including logs) back to the local mirror automatically once the job completes.

---

## Sample SLURM script

Minimal templates live under `src/koa_cli/templates/`. Start from `basic_job.slurm` and adapt the resources, modules, and commands to your workload (including any `#SBATCH --gres` lines you require). The CLI sets `KOA_ML_RESULTS_ROOT` automatically so jobs can collect outputs in the directory that `koa runs sync` mirrors locally once they finish.

Running `koa init` also drops a project-specific `scripts/basic_job.slurm` and `scripts/setup_env.sh` that you can customise; they mirror the global defaults captured by `koa setup`. The default config watches files like `scripts/setup_env.sh`, `requirements.txt`, and `pyproject.toml`, so changing any of them automatically triggers a virtualenv rebuild on the next submission.

---

## Development

Install development tooling with:

```bash
pip install -e .[dev]
ruff check
pytest
```

Contributions are welcome via pull request.
