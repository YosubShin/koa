# KOA-ML Environment Configuration
# Copy this file to .env and fill in your values
# Note: .env is gitignored and will not be committed

# ============================================================================
# KOA HPC Configuration
# ============================================================================

# Remote working directory on KOA (default: $HOME/koa-ml)
KOA_ML_WORKDIR=/home/your-username/koa-ml

# Python virtual environment path on KOA (default: $HOME/koa-ml/.venv)
KOA_ML_VENV=/home/your-username/koa-ml/.venv

# Python module to load on KOA (default: lang/Python/3.11.5-GCCcore-13.2.0)
KOA_PYTHON_MODULE=lang/Python/3.11.5-GCCcore-13.2.0

# CUDA module to load on KOA (optional, default: system/CUDA/12.2.0)
# KOA_CUDA_MODULE=cuda/12.1

# ============================================================================
# API Keys & Authentication
# ============================================================================

# HuggingFace token for accessing gated models (optional)
# Get your token from: https://huggingface.co/settings/tokens
# HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx

# Weights & Biases API key for experiment tracking (optional)
# Get your key from: https://wandb.ai/authorize
# WANDB_API_KEY=xxxxxxxxxxxxxxxxxxxxx

# WANDB project and entity (optional)
# WANDB_PROJECT=koa-ml-experiments
# WANDB_ENTITY=your-username

# ============================================================================
# HuggingFace Configuration
# ============================================================================

# Disable HuggingFace telemetry (recommended for HPC)
HF_HUB_DISABLE_TELEMETRY=1

# Disable HF Transfer (may cause issues on some HPC systems)
HF_HUB_ENABLE_HF_TRANSFER=0
HF_HUB_DISABLE_HF_TRANSFER=1

# HuggingFace cache directory (optional, useful for shared storage)
# HF_HOME=/mnt/lustre/koa/scratch/your-username/hf_cache

# ============================================================================
# PyTorch Configuration
# ============================================================================

# CUDA memory allocation strategy (helps with fragmentation)
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# ============================================================================
# Evaluation Configuration
# ============================================================================

# Default output format for evaluation results (json, csv, tsv, or multiple)
# EVAL_OUTPUT_FORMAT=json,csv

# ============================================================================
# Development & Debugging
# ============================================================================

# Enable debug logging (uncomment for verbose output)
# LOG_LEVEL=DEBUG

# Disable progress bars in non-interactive environments
# TQDM_DISABLE=1
